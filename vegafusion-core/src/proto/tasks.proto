syntax = "proto3";
package tasks;

import "expression.proto";
import "transforms.proto";

// ## Task Value
message TaskValue {
  oneof data {
  /*
   * Representation of scalar as single column, single row, record batch in Arrow IPC format
   */
    bytes scalar = 1;

  /*
   * Serialized Arrow record batch in Arrow IPC format
   */
    bytes table = 2;
  }
}

// ## Variable
enum VariableNamespace {
  Signal = 0;
  Data = 1;
  Scale = 2;
}

message Variable {
  string name = 1;
  VariableNamespace namespace = 2;
}

// ## Scan URL Task
message ParseFieldSpec {
  string name = 1;
  string datatype = 2;
}

message ParseFieldSpecs {
  repeated ParseFieldSpec specs = 1;
}

message ScanUrlFormat {
  /*
   * The data format type. The currently supported data formats are json (the default),
   * csv (comma-separated values), tsv (tab-separated values), dsv (delimited text files),
   * and topojson.
   */
  optional string type = 1;

  /*
   * JSON encoded string:
   * If set to auto, perform automatic type inference to determine the desired data types.
   * Alternatively, a parsing directive object can be provided for explicit data types.
   * Each property of the object corresponds to a field name, and the value to the desired data type
   * (one of "boolean", "date", "number" or "string"). For example, "parse": {"modified_on": "date"}
   * parses the modified_on field in each input record as a Date value. Specific date formats can
   * be provided (e.g., {"foo": "date:'%m%d%Y'"}), using the d3-time-format syntax. UTC date format
   * parsing is supported similarly (e.g., {"foo": "utc:'%m%d%Y'"}).
   */
  oneof parse {
    string string = 2;
    ParseFieldSpecs object = 3;
  };

  optional string property = 4;
  repeated string header = 5;
  optional string delimiter = 6;
  optional string feature = 7;
}

message DataUrlTask {
  oneof url {
    string string = 1;
    expression.Expression expr = 2;
  };
  int32 batch_size = 3;
  ScanUrlFormat format_type = 4;
  transforms.TransformPipeline pipeline = 5;
}

// ## Inline values task
message DataValuesTask {
  bytes values = 1;
  ScanUrlFormat format_type = 2;
  transforms.TransformPipeline pipeline = 3;
}

// ## Transform Task
message DataSourceTask {
  string source = 1;
  transforms.TransformPipeline pipeline = 2;
}

// ## Signal Task
message SignalTask {
  expression.Expression expr = 2;
}

// ## Timezone config
message TzConfig {
  string local_tz = 1;
  optional string default_input_tz = 2;
}

// ## Top-level Task
message Task {
  Variable variable = 1;
  repeated uint32 scope = 2;
  oneof task_kind {
    TaskValue value = 3;
    DataValuesTask data_values = 4;
    DataUrlTask data_url = 5;
    DataSourceTask data_source = 6;
    SignalTask signal = 7;
  }
  TzConfig tz_config = 8;
}


// ## Task Graph
message IncomingEdge {
  uint32 source = 1;
  optional uint32 output = 2;
}

message OutgoingEdge {
  uint32 target = 1;
  bool propagate = 2;
}

message TaskNode {
  Task task = 1;
  repeated IncomingEdge incoming = 2;
  repeated OutgoingEdge outgoing = 3;
  uint64 id_fingerprint = 4;
  uint64 state_fingerprint = 5;
}

message TaskGraph {
  repeated TaskNode nodes = 1;
}

message NodeValueIndex {
  uint32 node_index = 1;
  optional uint32 output_index = 2;
}

message TaskGraphValueRequest {
  TaskGraph task_graph = 1;
  repeated NodeValueIndex indices = 2;
  repeated InlineDataset inline_datasets = 3;
}

message ResponseTaskValue {
  Variable variable = 1;
  repeated uint32 scope = 2;
  TaskValue value = 3;
}

message TaskGraphValueResponse {
  repeated ResponseTaskValue response_values = 1;
}

message InlineDatasetTable {
  // Inline dataset name
  string name = 1;
  // Serialized Arrow record batch in Arrow IPC format
  bytes table = 2;
}

message InlineDatasetPlan {
  // Inline dataset name
  string name = 1;
  // Serialized DataFusion plan in protobuf format
  bytes plan = 2;
}

message InlineDataset {
  oneof dataset {
    InlineDatasetTable table = 1;
    InlineDatasetPlan plan = 2;
  }
}